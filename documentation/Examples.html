<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Examples &mdash; ELEKTRONN</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1rc',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/elektronnfavicon.ico"/>
    <link rel="top" title="ELEKTRONN" href="index.html" />
    <link rel="next" title="Practical Introduction to Neural Networks" href="IntroNN.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
  </head>
  <body>

<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="index.html"><img src="_static/elektronn.png" border="0" alt="sampledoc"/></a>
</div>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="IntroNN.html" title="Practical Introduction to Neural Networks"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="Installation.html" title="Installation"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">ELEKTRONN</a> &raquo;</li> 
      </ul>
    </div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="examples">
<span id="id1"></span><h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>This page gives examples other than using the &#8220;big&#8221; <a class="reference internal" href="Pipeline.html#pipeline"><em>data pipeline</em></a>. They examples are also intended to give an idea of ways how custom network architectures could be created and trained. To understand the examples basic knowledge of neural networks (e.g. from <a class="reference internal" href="IntroNN.html#training"><em>Practical Introduction to Neural Networks</em></a>) is required.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#mnist-example" id="id3">MNIST Example</a></li>
<li><a class="reference internal" href="#auto-encoder-example" id="id4">Auto encoder Example</a></li>
<li><a class="reference internal" href="#rnn-example" id="id5">RNN Example</a></li>
</ul>
</div>
<div class="section" id="mnist-example">
<span id="mnist"></span><h2><a class="toc-backref" href="#id3">MNIST Example</a><a class="headerlink" href="#mnist-example" title="Permalink to this headline">¶</a></h2>
<p>MNIST is a benchmark data set for digit recognition/classification. State of the art benchmarks for comparison can be found <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">here</a>. The data will be automatically downloaded but can also be downloaded from <a class="reference external" href="http://www.elektronn.org/downloads/mnist.pkl.gz">here</a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For all examples you must download and unpack the MNIST files. Additionally you must update the path to the MNIST file in the example scripts / configs.</p>
</div>
<div class="section" id="cnn-with-built-in-pipeline">
<h3>CNN with built-in Pipeline<a class="headerlink" href="#cnn-with-built-in-pipeline" title="Permalink to this headline">¶</a></h3>
<p>In ELEKTRONN&#8217;s <tt class="docutils literal"><span class="pre">examples</span></tt> folder is a file <tt class="docutils literal"><span class="pre">MNIST_CNN_warp_config.py</span></tt>. This is a configuration for <em>img-scalar</em> training and it uses a different data class than the &#8220;big&#8221; pipeline for neuro data. In case the of an alternative data pipeline the options for data loading and batch creation are given given by keyword argument dictionaries in the <tt class="docutils literal"><span class="pre">Data</span> <span class="pre">Alternative</span></tt> section of the config:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">data_class_name</span>      <span class="o">=</span> <span class="s">&#39;MNISTData&#39;</span>
<span class="n">data_load_kwargs</span>     <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">convert2image</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">warp_on</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">shift_augment</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_batch_kwargs</span>    <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</pre></div>
</div>
<p>This configuration results in:</p>
<blockquote>
<div><ul class="simple">
<li>Initialising a data class adapted for MNIST from <tt class="xref py py-mod docutils literal"><span class="pre">training.traindata</span></tt></li>
<li>Downloading the MNIST data automatically if path is <tt class="docutils literal"><span class="pre">None</span></tt> or loading from the specified path</li>
<li>Reshaping the &#8220;flat&#8221; training examples (they are stored as vectors of length 784) to <tt class="docutils literal"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></tt> matrices i.e. images</li>
<li>Data augmentation through warping (see <a class="reference internal" href="IntroNN.html#warping"><em>Data Augmentation</em></a>): for each batch in a training iteration random deformation parameters are sampled and the corresponding transformations are applied to the images in a background process.</li>
<li>Data augmentation through translation: <tt class="docutils literal"><span class="pre">shift_augment</span></tt> crops the <tt class="docutils literal"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></tt> images  to <tt class="docutils literal"><span class="pre">26</span> <span class="pre">x</span> <span class="pre">26</span></tt> (you may notice this in the printed output). The cropping allows to choose from which origin to crop from (like applying small translations), in this example the data set size is inflated by factor <tt class="docutils literal"><span class="pre">4</span></tt>.</li>
<li>For the function <tt class="docutils literal"><span class="pre">getbatch</span></tt> no additional kwargs are required (the warping and so on was specified already with the initialisation).</li>
</ul>
</div></blockquote>
<p>The architecture of the NN is determined by:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">n_dim</span>           <span class="o">=</span> <span class="mi">2</span>
<span class="n">desired_input</span>   <span class="o">=</span> <span class="mi">26</span>
<span class="n">filters</span>         <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>                 <span class="c"># filter shapes in (x,y)/(x,y,z)-order</span>
<span class="n">pool</span>            <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>                 <span class="c"># pool shapes in (x,y)/(x,y,z)-order</span>
<span class="n">nof_filters</span>     <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">32</span><span class="p">]</span>               <span class="c"># number of feature maps per layer</span>
<span class="n">MLP_layers</span>       <span class="o">=</span> <span class="p">[</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">]</span>            <span class="c"># numbers of filters for perceptron layers (after conv layers)</span>
</pre></div>
</div>
<p>This is 2D CNN with two conv layers (each has <tt class="docutils literal"><span class="pre">3</span> <span class="pre">x</span> <span class="pre">3</span></tt> 2D filter) and two fully connected layers each with 300 neurons. As MNIST has 10 classes, an output layer with 10 neurons is automatically added, and not specified here.</p>
<p>To run the example, make a copy of the config file and adjust the paths. Then run the <tt class="docutils literal"><span class="pre">elektronn-train</span></tt> script, and pass the path of your config file:</p>
<div class="highlight-python"><div class="highlight"><pre>elektronn-train [config=&lt;/path/to_config_file&gt;] [ gpu={Auto|False|&lt;int&gt;}]
</pre></div>
</div>
<p>The output should read like this:</p>
<div class="highlight-python"><div class="highlight"><pre>Reading config-file ../elektronn/examples/MNIST_CNN_warp_config.py
WARNING: Receptive Fields are not centered with even field of view (10)
WARNING: Receptive Fields are not centered with even field of view (10)
Selected patch-size for CNN input: Input: [26, 26]
Layer/Fragment sizes: [[12, 5], [12, 5]]
Unpooled Layer sizes: [[24, 10], [24, 10]]
Receptive fields:     [[4, 10], [4, 10]]
Strides:              [[2, 4], [2, 4]]
Overlap:              [[2, 6], [2, 6]]
Offset:               [5.0, 5.0].
If offset is non-int: output neurons lie centered on input neurons,they have an odd FOV

Overwriting existing save directory: /home/mfk/CNN_Training/2D/MNIST_example_warp/
Using gpu device 0: GeForce GTX TITAN
Load ELEKTRONN Core
10-class Data Set: #training examples: 200000 and #validing: 10000
MNIST data is converted/augmented to shape (1, 26, 26)
------------------------------------------------------------
Input shape   =  (50, 1, 26, 26) ; This is a 2 dimensional NN
---
2DConv: input= (50, 1, 26, 26)        filter= (16, 1, 3, 3)
Output = (50, 16, 12, 12) Dropout OFF, Act: relu pool: max
Computational Cost: 4.1 Mega Ops
---
2DConv: input= (50, 16, 12, 12)       filter= (32, 16, 3, 3)
Output = (50, 32, 5, 5) Dropout OFF, Act: relu pool: max
Computational Cost: 23.0 Mega Ops
---
PerceptronLayer( #Inputs = 800 #Outputs = 300 )
Computational Cost: 12.0 Mega Ops
---
PerceptronLayer( #Inputs = 300 #Outputs = 300 )
Computational Cost: 4.5 Mega Ops
---
PerceptronLayer( #Inputs = 300 #Outputs = 10 )
Computational Cost: 150.0 kilo Ops
---
GLOBAL
Computational Cost: 43.8 Mega Ops
Total Count of trainable Parameters: 338410
Building Computational Graph took 0.030 s
Compiling output functions for nll target:
        using no class_weights
        using no example_weights
        using no lazy_labels
        label propagation inactive
</pre></div>
</div>
<p>A few comments on the expected output before training:</p>
<blockquote>
<div><ul class="simple">
<li>There will be a warning that receptive fields are not centered (the neurons in the last conv layer lie spatially &#8220;between&#8221; the neurons of the input layer). This is ok because this training task does require localisation of objects. All local information is discarded anyway when the fully connected layers are put after the conv layers.</li>
<li>The information of <tt class="xref py py-func docutils literal"><span class="pre">net.netutils.CNNCalculator()</span></tt> is printed first, i.e. the layer sizes, receptive fields etc.</li>
<li>Although MNIST contains only 50000 training examples, it will print 200000 because of the shift augmentation, which is done when loading the data</li>
<li>For image training, an auxiliary dimension for the (colour) channel is introduced.</li>
<li>The input shape <tt class="docutils literal"><span class="pre">(50,</span> <span class="pre">1,</span> <span class="pre">26,</span> <span class="pre">26)</span></tt> indicates that the batch size is 50, the number of channels is just 1 and the image extent is <tt class="docutils literal"><span class="pre">26</span> <span class="pre">x</span> <span class="pre">26</span></tt>.</li>
<li>You can observe that the first layer outputs an image of size is <tt class="docutils literal"><span class="pre">12</span> <span class="pre">x</span> <span class="pre">12</span></tt>: the convolution with filter size 3 reduces 26 to 24, then the maxpooling by factor 2 reduces 24 to 12.</li>
<li>After the last conv layer everything except the batch dimension is flattened to be feed into a fully connected layer: <tt class="docutils literal"><span class="pre">32</span> <span class="pre">x</span> <span class="pre">5</span> <span class="pre">x</span> <span class="pre">5</span> <span class="pre">==</span> <span class="pre">800</span></tt>. If the image extent is not sufficiently small before doing this (e.g. <tt class="docutils literal"><span class="pre">10</span> <span class="pre">x</span> <span class="pre">10</span> <span class="pre">==</span> <span class="pre">100</span></tt>) this will be a bottleneck and introduce <strong>huge</strong> weight matrices for the fully connected layer; more poolings must be used then.</li>
</ul>
</div></blockquote>
<div class="section" id="results-discussion">
<h4>Results &amp; Discussion<a class="headerlink" href="#results-discussion" title="Permalink to this headline">¶</a></h4>
<p>The values in the example file should give a good result after about 10-15 minutes on a recent GPU, but you are invited to play around with the network architecture and meta-parameters such as the learning rate. To watch the progress (in a nicer way than the reading the printed numbers on the console) go to the save directory and have a look at the plots. Every time a new line is printed in the console, the plot gets updated as well.</p>
<p><strong>If you had not used warping</strong> the progress of the training would look like this:</p>
<blockquote>
<div><div class="figure align-center">
<img alt="_images/MNIST_Nowarp.Errors.png" src="_images/MNIST_Nowarp.Errors.png" />
<p class="caption">Withing a few minutes the <em>training</em> error goes to 0 whereas the <em>validation</em> error  stays on a higher level.</p>
</div>
</div></blockquote>
<p>The spread between training and validation set (a partition of the data not presented as training examples) indicates a kind of over-fitting. But actually the over-fitting observed here is not as bad as it could be: because the training error is 0 the gradients are close to 0 - no weight updates are made for 0 gradient, so the training stops &#8220;automatically&#8221; at this point. For different data sets the training error might not reach 0 and weight updates are made all the time resulting in a validation error that goes <strong>up</strong> after some time - this would be real over-fitting.</p>
<p>A common regularisation technique to prevent over-fitting is drop out which is also implemented in ELEKETRONN. But since MNIST data are images, we want to demonstrate the use of warping instead in this example.</p>
<p>Warping makes the training goal more difficult, therefore the CNN has to learn its task &#8220;more thoroughly&#8221;. This greatly reduces the spread between training and validation set. Training also takes slightly more time. And because the task is more difficult the training error will not reach 0 anymore. The validation error is also high during training, since the CNN is devoting resources to solving the difficult (warped) training set at the expense of generalization to &#8220;normal&#8221; data of the validation set.</p>
<p>The actual boost in (validation) performance comes when the warping is turned off and the training is fine-tuned with a smaller learning rate. Wait untill the validation error approximately plateaus, then interrupt the training using <tt class="docutils literal"><span class="pre">ctrl+c</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="o">.</span><span class="n">warp_on</span> <span class="o">=</span> <span class="bp">False</span> <span class="c"># Turn off warping</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">setlr</span> <span class="mf">0.002</span>          <span class="c"># Lower learning rate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span>                    <span class="c"># quit console to continue training</span>
</pre></div>
</div>
<p>This stops the warping for further training and lowers the learning rate.
The resulting training progress would look like this:</p>
<blockquote>
<div><div class="figure align-center">
<img alt="_images/MNIST_warp.Errors.png" src="_images/MNIST_warp.Errors.png" />
<p class="caption">The training was interrupted after ca. 130000 iterations. Turning off warping reduced both errors to their final level (after the gradient is 0 again, no progress can be made).</p>
</div>
</div></blockquote>
<p>Because our decisions on the best learning rate and the best point to stop warping have been influenced by the validation set (we could somehow over-fit to the validation set), the actual performance is evaluated on a separate, third set, the <em>test</em> set (we should really only ever look at the test error when we have decided on a training setup/schedule, the test set is not meant to influence training at all).</p>
<p>Stop the training using <tt class="docutils literal"><span class="pre">ctrl+c</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="bp">self</span><span class="o">.</span><span class="n">testModel</span><span class="p">(</span><span class="s">&#39;test&#39;</span><span class="p">)</span>
<span class="go">(&lt;NLL&gt;, &lt;Errors&gt;)</span>
</pre></div>
</div>
<p>The result should be competitive - around 0.5% error, i.e. 99.5% accuracy.</p>
</div>
</div>
<div class="section" id="mlp-with-built-in-pipeline">
<h3>MLP with built-in Pipeline<a class="headerlink" href="#mlp-with-built-in-pipeline" title="Permalink to this headline">¶</a></h3>
<p>In the spirit of the above example, MNIST can also be trained with a pure multi layer perceptron (MLP) without convolutions. The images are then just flattened vectors (&#8211;&gt; <em>vect-scalar</em> mode). There is a config file <tt class="docutils literal"><span class="pre">MNIST_MLP_config.py</span></tt> in the <tt class="docutils literal"><span class="pre">Examples</span></tt> folder. This method can also be applied for any other non-image data, e.g. predicting income from demographic features.</p>
</div>
<div class="section" id="standalone-cnn">
<h3>Standalone CNN<a class="headerlink" href="#standalone-cnn" title="Permalink to this headline">¶</a></h3>
<p>If you think the big pipeline and long configuration file is a bit of an overkill for good old MNIST we have an alternative lightweight example in the file <tt class="docutils literal"><span class="pre">MNIST_CNN_standalone.py</span></tt> of the <tt class="docutils literal"><span class="pre">Examples</span></tt> folder. This example illustrates what (in a slightly more elaborate way) happens under the hood of the big pipeline.</p>
<p>First we import the required classes and initialise a training data object from <tt class="xref py py-mod docutils literal"><span class="pre">training.traindata</span></tt> (which we actually used above, too). It does not more than loading the training, validation and testing data and sample batches randomly - all further options e.g. for augmentation are not used here:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">elektronn.training.traindata</span> <span class="kn">import</span> <span class="n">MNISTData</span>
<span class="kn">from</span> <span class="nn">elektronn.net.convnet</span> <span class="kn">import</span> <span class="n">MixedConvNN</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">MNISTData</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">&#39;~/devel/ELEKTRONN/Examples/mnist.pkl&#39;</span><span class="p">,</span><span class="n">convert2image</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">shift_augment</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Next we set up the Neural Network. Each method of <tt class="docutils literal"><span class="pre">cnn</span></tt> has much more options which are explained in the API doc. Start with similar code if you want to create customised NNs:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">cnn</span> <span class="o">=</span> <span class="n">MixedConvNN</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span><span class="n">input_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c"># input_depth: only 1 gray channel (no RGB or depth)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addConvLayer</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">pool_shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;abs&quot;</span><span class="p">)</span> <span class="c"># (nof, filtersize)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addConvLayer</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pool_shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;abs&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;abs&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;abs&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;abs&quot;</span><span class="p">)</span> <span class="c"># need 10 outputs as there are 10 classes in the data set</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">compileOutputFunctions</span><span class="p">()</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">setOptimizerParams</span><span class="p">(</span><span class="n">SGD</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;LR&#39;</span><span class="p">:</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="s">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c"># LR: learning rate</span>
</pre></div>
</div>
<p>Finally, the training loop which applies weight updates in every iteration:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
  <span class="n">d</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">getbatch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">loss</span><span class="p">,</span> <span class="n">loss_instance</span><span class="p">,</span> <span class="n">time_per_step</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">trainingStep</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&quot;SGD&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">100</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_error</span><span class="p">,</span> <span class="n">valid_predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">get_error</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">valid_d</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">valid_l</span><span class="p">)</span>
        <span class="k">print</span> <span class="s">&quot;update:&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s">&quot;; Validation loss:&quot;</span><span class="p">,</span><span class="n">valid_loss</span><span class="p">,</span> <span class="s">&quot;Validation error:&quot;</span><span class="p">,</span><span class="n">valid_error</span><span class="o">*</span><span class="mf">100.</span><span class="p">,</span><span class="s">&quot;%&quot;</span>

<span class="n">loss</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">get_error</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_d</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">test_l</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;Test loss:&quot;</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span> <span class="s">&quot;Test error:&quot;</span><span class="p">,</span><span class="n">error</span><span class="o">*</span><span class="mf">100.</span><span class="p">,</span><span class="s">&quot;%&quot;</span>
</pre></div>
</div>
<p>Of course the performance of this setup is not as good of the model above, but feel free tweak - how about dropout? Simply add <tt class="docutils literal"><span class="pre">enable_dropout=True</span></tt> to the cnn initialisation: all layers have by default a dropout rate of 0.5 - unless it is suppressed with <tt class="docutils literal"><span class="pre">force_no_dropout=True</span></tt> when adding a particular layer (it should not be used in the last layer). Don&#8217;t forget to set the dropout rates to 0 while estimating the performance and to their old value afterwards (the methods <tt class="docutils literal"><span class="pre">cnn.getDropoutRates</span></tt> and <tt class="docutils literal"><span class="pre">cnn.setDropoutRates</span></tt> might be useful). Hint: for dropout, a different activation function than <tt class="docutils literal"><span class="pre">abs</span></tt>, more neurons per layer and more training iterations might perform better... you can try adapting it yourself or find a ready setup with drop out in the <tt class="docutils literal"><span class="pre">examples</span></tt> folder.</p>
</div>
</div>
<div class="section" id="auto-encoder-example">
<span id="autoencoder"></span><h2><a class="toc-backref" href="#id4">Auto encoder Example</a><a class="headerlink" href="#auto-encoder-example" title="Permalink to this headline">¶</a></h2>
<p>This examples also uses MNIST data, but this time the task is not classification but compression. The input images have shape <tt class="docutils literal"><span class="pre">28</span> <span class="pre">x</span> <span class="pre">28</span></tt> but we will regard them as 784 dimensional vectors. The NN is shaped like an hourglass: the number of neurons decreases from 784 input neurons to 50 internal neurons in the central layer. Then the number increases symmetrically to 784 for the output. The training target is to reproduce the input in the output layer (i.e. the labels are identical to the data). Because the inputs are float numbers, so is the output and this is a regression problem. The first part of the auto encoder compresses the information and the second part decompresses it. The weights of both parts are shared, i.e. the weight matrix of each decompression layer is the transposed weight matrix of the corresponding compression layer, and updates are made simultaneously in both layers. For constructing an auto encoder the method <tt class="docutils literal"><span class="pre">cnn.addTiedAutoencoderChain</span></tt> is used.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">elektronn.training.traindata</span> <span class="kn">import</span> <span class="n">MNISTData</span>
<span class="kn">from</span> <span class="nn">elektronn.net.convnet</span> <span class="kn">import</span> <span class="n">MixedConvNN</span>
<span class="kn">from</span> <span class="nn">elektronn.net.introspection</span> <span class="kn">import</span> <span class="n">embedMatricesInGray</span>


<span class="c"># Load Data #</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">MNISTData</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">&#39;/docs/devel/ELEKTRONN/elektronn/examples/mnist.pkl&#39;</span><span class="p">,</span><span class="n">convert2image</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">shift_augment</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


<span class="c"># Load Data #</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">MNISTData</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">&#39;~/devel/ELEKTRONN/Examples/mnist.pkl&#39;</span><span class="p">,</span><span class="n">convert2image</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">shift_augment</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c"># Create Autoencoder #</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">cnn</span> <span class="o">=</span> <span class="n">MixedConvNN</span><span class="p">((</span><span class="mi">28</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span><span class="n">input_depth</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">addTiedAutoencoderChain</span><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">,</span><span class="n">input_noise</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">add_layers_to_network</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">compileOutputFunctions</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s">&quot;regression&quot;</span><span class="p">)</span>  <span class="c">#compiles the cnn.get_error function as well</span>
<span class="n">cnn</span><span class="o">.</span><span class="n">setOptimizerParams</span><span class="p">(</span><span class="n">SGD</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;LR&#39;</span><span class="p">:</span> <span class="mf">5e-1</span><span class="p">,</span> <span class="s">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
  <span class="n">d</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">getbatch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">loss</span><span class="p">,</span> <span class="n">loss_instance</span><span class="p">,</span> <span class="n">time_per_step</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">trainingStep</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&quot;SGD&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">100</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">&quot;update:&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s">&quot;; Training error:&quot;</span><span class="p">,</span><span class="n">loss</span>

<span class="n">loss</span><span class="p">,</span>  <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">get_error</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">valid_d</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">valid_d</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">embedMatricesInGray</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">valid_d</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">200</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;none&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">recon</span> <span class="o">=</span> <span class="n">embedMatricesInGray</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">200</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)),</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">recon</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;none&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Reconstruction&#39;</span><span class="p">)</span>

<span class="n">cnn</span><span class="o">.</span><span class="n">saveParameters</span><span class="p">(</span><span class="s">&#39;AE-pretraining.param&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The above NN learns to compress the 784 pixels of an image to a 50 dimensional code (ca. 15x). The quality of the reconstruction can be inspected from plotting the images and comparing them to the original input:</p>
<blockquote>
<div><div class="figure align-center">
<img alt="_images/DAE.png" src="_images/DAE.png" />
<p class="caption">Left input data (from validation set) and right reconstruction. The reconstruction values have been slightly rescaled for better visualisation.</p>
</div>
</div></blockquote>
<p>The compression part of the auto encoder can be used to reduce the dimension of a data vector, while still preserving the information necessary to reconstruct the original data.</p>
<p>Often training data (e.g. lots of images of digits) are vastly available but nobody has taken the effort to create training labels for all of them. This is when auto encoders can be useful: train an auto encoder on the unlabelled data and use the learnt weights to initialise a NN for classification (aka pre-training).The classifcation NN does not have to learn a good internal data representation from scratch. To fine-tune the weights for classification (mainly in the additional output layer), only a small fraction of the examples must be labelled. To construct a pre-trained NN:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cnn</span><span class="o">.</span><span class="n">saveParameters</span><span class="p">(</span><span class="s">&#39;AE-pretraining.param&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="n">cnn</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="c"># save the parameters for the compression part</span>
<span class="n">cnn2</span> <span class="o">=</span> <span class="n">MixedConvNN</span><span class="p">((</span><span class="mi">28</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span><span class="n">input_depth</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="c"># Create a new NN</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">addPerceptronLayer</span><span class="p">(</span> <span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="s">&quot;tanh&quot;</span><span class="p">)</span> <span class="c"># Add a layer for 10-class classificaion</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">compileOutputFunctions</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s">&quot;nll&quot;</span><span class="p">)</span>  <span class="c">#compiles the cnn.get_error function as well # target function nll for classification</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">setOptimizerParams</span><span class="p">(</span><span class="n">SGD</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;LR&#39;</span><span class="p">:</span> <span class="mf">0.005</span><span class="p">,</span> <span class="s">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cnn2</span><span class="o">.</span><span class="n">loadParameters</span><span class="p">(</span><span class="s">&#39;AE-pretraining.param&#39;</span><span class="p">)</span> <span class="c"># This overloads only the first 3 layers,because the file contains only params for 3 layers</span>

<span class="c"># Do training steps with the labels like</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
  <span class="n">d</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">getbatch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="n">cnn2</span><span class="o">.</span><span class="n">trainingStep</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">&quot;SGD&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rnn-example">
<h2><a class="toc-backref" href="#id5">RNN Example</a><a class="headerlink" href="#rnn-example" title="Permalink to this headline">¶</a></h2>
<p>Coming soon</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Examples</a><ul>
<li><a class="reference internal" href="#mnist-example">MNIST Example</a><ul>
<li><a class="reference internal" href="#cnn-with-built-in-pipeline">CNN with built-in Pipeline</a><ul>
<li><a class="reference internal" href="#results-discussion">Results &amp; Discussion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlp-with-built-in-pipeline">MLP with built-in Pipeline</a></li>
<li><a class="reference internal" href="#standalone-cnn">Standalone CNN</a></li>
</ul>
</li>
<li><a class="reference internal" href="#auto-encoder-example">Auto encoder Example</a></li>
<li><a class="reference internal" href="#rnn-example">RNN Example</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="Installation.html"
                        title="previous chapter">Installation</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="IntroNN.html"
                        title="next chapter">Practical Introduction to Neural Networks</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/Examples.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="IntroNN.html" title="Practical Introduction to Neural Networks"
             >next</a> |</li>
        <li class="right" >
          <a href="Installation.html" title="Installation"
             >previous</a> |</li>
        <li><a href="index.html">ELEKTRONN</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, Gregor Urban, Marius F Killinger.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>